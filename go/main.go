package main

import (
	"encoding/json"
	"errors"
	"fmt"
	"log"
	"net/http"
	"os"
	"regexp"
	"runtime"
	"strings"
	"time"

	"github.com/tebeka/selenium"
	"github.com/tebeka/selenium/chrome"
)

var (
	// chromedriver ìœ„ì¹˜
	chromeDriverPath = "/usr/bin/chromedriver"
	port             = 9515
)

func init() {
	// macOS í™˜ê²½(í…ŒìŠ¤íŠ¸ í™˜ê²½)ì¸ ê²½ìš° pathë¥¼ /opt/homebrew/bin/chromedriver ë¡œ ì„¤ì •
	if runtime.GOOS == "darwin" {
		log.Println("ğŸ macOS detected. Setting chromedriver path to /opt/homebrew/bin/chromedriver")
		chromeDriverPath = "/opt/homebrew/bin/chromedriver"
	} else {
		log.Println("ğŸ§ Linux detected. Using default chromedriver path.")
	}
}

// initWebDriverëŠ” ê³µí†µ WebDriver ì´ˆê¸°í™” ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤.
func initWebDriver() (selenium.WebDriver, func(), error) {
	// Chrome ì˜µì…˜ ì„¤ì •
	caps := selenium.Capabilities{"browserName": "chrome"}
	chromeCaps := chrome.Capabilities{
		Args: []string{
			"--headless=new",
			"--disable-gpu",
			"--no-sandbox",
			"--window-size=1280,1024",
			"--disable-dev-shm-usage",
			"--lang=ko-KR,ko",
			"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
		},
	}
	caps.AddChrome(chromeCaps)

	// ChromeDriver ì„œë¹„ìŠ¤ ì‹œì‘
	service, err := selenium.NewChromeDriverService(chromeDriverPath, port)
	if err != nil {
		return nil, nil, fmt.Errorf("Failed to start ChromeDriver: %v", err)
	}

	// ì¢…ë£Œ í•¨ìˆ˜: service.Stop() í˜¸ì¶œ
	quitFunc := func() {
		service.Stop()
	}

	// WebDriver ì—°ê²°
	wd, err := selenium.NewRemote(caps, fmt.Sprintf("http://localhost:%d/wd/hub", port))
	if err != nil {
		quitFunc()
		return nil, nil, fmt.Errorf("Failed to connect to WebDriver: %v", err)
	}

	return wd, quitFunc, nil
}

type TweetData struct {
	Text           string   `json:"text"`
	Images         []string `json:"images"`
	Username       string   `json:"username"`
	UserNickname   string   `json:"user_nickname"`
	UserProfileImg string   `json:"user_profile_img"`
	MetaTag        string   `json:"meta_tag"`
	Links          []string `json:"links"` // âœ… ì—¬ëŸ¬ ë§í¬
}

func main() {

	http.HandleFunc("/scrape-twitter", TweetScrapeHandler)
	http.HandleFunc("/meta", MetaHandler)
	fmt.Println("ğŸš€ Server running on http://localhost:18081")
	log.Fatal(http.ListenAndServe(":18081", nil))
}

func TweetScrapeHandler(w http.ResponseWriter, r *http.Request) {
	tweetURL := r.URL.Query().Get("url")
	if tweetURL == "" {
		http.Error(w, "Missing 'url' query parameter", http.StatusBadRequest)
		return
	}

	// Chrome options
	caps := selenium.Capabilities{"browserName": "chrome"}
	caps.AddChrome(chrome.Capabilities{Args: []string{
		"--headless=new",
		"--disable-gpu",
		"--no-sandbox",
		"--window-size=1280,1024",
		"--disable-dev-shm-usage", // ì¶”ê°€ëœ í”Œë˜ê·¸
		"--lang=ko-KR,ko",
		"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
	}})

	// Start chromedriver
	service, err := selenium.NewChromeDriverService(chromeDriverPath, port)
	if err != nil {
		http.Error(w, fmt.Sprintf("Failed to start ChromeDriver: %v", err), http.StatusInternalServerError)
		return
	}
	defer service.Stop()

	// Connect to WebDriver
	wd, err := selenium.NewRemote(caps, fmt.Sprintf("http://localhost:%d/wd/hub", port))
	if err != nil {
		http.Error(w, fmt.Sprintf("Failed to connect to WebDriver: %v", err), http.StatusInternalServerError)
		return
	}
	defer wd.Quit()

	// Scrape tweet
	tweetData, err := ScrapeTweet(wd, tweetURL)
	if err != nil {
		http.Error(w, fmt.Sprintf("Failed to scrape tweet: %v", err), http.StatusInternalServerError)
		return
	}

	// Return as JSON
	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(tweetData)
}

// MetaHandlerëŠ” /meta?url= ê²½ë¡œì—ì„œ ë©”íƒ€ íƒœê·¸ ìŠ¤í¬ë˜í•‘ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
func MetaHandler(w http.ResponseWriter, r *http.Request) {

	pageURL := r.URL.Query().Get("url")
	if pageURL == "" {
		http.Error(w, "Missing 'url' query parameter", http.StatusBadRequest)
		return
	}

	wd, quitFunc, err := initWebDriver()
	if err != nil {
		http.Error(w, err.Error(), http.StatusInternalServerError)
		return
	}
	defer quitFunc()
	defer wd.Quit()

	metaData, err := ScrapeMeta(wd, pageURL)
	if err != nil {
		http.Error(w, fmt.Sprintf("Failed to scrape meta: %v", err), http.StatusInternalServerError)
		return
	}

	w.Header().Set("Content-Type", "application/json")
	json.NewEncoder(w).Encode(metaData)
}

func findTextByXPath(wd selenium.WebDriver, xpath string) string {

	elem, err := wd.FindElement(selenium.ByXPATH, xpath)
	if err != nil {
		log.Printf("âŒ Error: Failed to find element: %v", err)
		return ""
	}
	text, err := elem.Text()
	if err != nil {
		return ""
	}
	return text
}

func findAttrByXPath(wd selenium.WebDriver, xpath, attr string) string {

	elem, err := wd.FindElement(selenium.ByXPATH, xpath)
	if err != nil {
		log.Printf("âŒ Error: Failed to find element: %v", err)
		return ""
	}
	val, err := elem.GetAttribute(attr)
	if err != nil {
		return ""
	}
	return val
}

func ScrapeTweet(wd selenium.WebDriver, url string) (*TweetData, error) {
	log.Printf("ğŸ“¥ í¬ë¡¤ë§ ì‹œì‘: %s", url)

	err := wd.Get(url)
	if err != nil {
		return nil, fmt.Errorf("failed to load URL: %w", err)
	}

	// source, err := wd.PageSource()
	// if err != nil {
	// 	log.Printf("âŒ Failed to get page source: %v\n", err)
	// } else {
	// 	log.Println("âœ… Page loaded. First 2000 chars:")
	// 	log.Println(source[:2000])
	// }

	// í˜ì´ì§€ íƒ€ì´í‹€ ì¶œë ¥
	title, _ := wd.Title()
	log.Printf("ğŸ“„ Title: %s", title)

	// í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
	for i := 0; i < 20; i++ {
		_, err := wd.FindElement(selenium.ByCSSSelector, "article")
		if err == nil {
			break
		}
		time.Sleep(500 * time.Millisecond)
	}

	// ì›¹í˜ì´ì§€ ë¡œë”© ìƒíƒœ í™•ì¸
	_, err = wd.FindElement(selenium.ByCSSSelector, "article")
	if err != nil {
		log.Println("âŒ Error: <article> íƒœê·¸ë¥¼ ëª» ì°¾ì•˜ì–´ìš”. ì•„ë§ˆ íŠ¸ìœ—ì´ ì•ˆ ë³´ì´ê±°ë‚˜ ë¦¬ë””ë ‰ì…˜ ëœ ê²ƒ ê°™ì•„ìš”. í˜ì´ì§€ ì†ŒìŠ¤ë¥¼ ì €ì¥í• ê²Œìš”.")

		// í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸° ë° íŒŒì¼ ì €ì¥
		source, err := wd.PageSource()
		if err != nil {
			log.Printf("í˜ì´ì§€ ì†ŒìŠ¤ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: %v", err)
		} else {
			err = os.WriteFile("page.html", []byte(source), 0644)
			if err != nil {
				log.Printf("íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: %v", err)
			} else {
				log.Println("í˜ì´ì§€ ì†ŒìŠ¤ê°€ 'page.html' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. docker í™˜ê²½ì¸ ê²½ìš° ./app/page.html íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
			}
		}
		return nil, fmt.Errorf("failed to find <article> element: %w", err)
	}
	currentURL, _ := wd.CurrentURL()
	log.Printf("ğŸŒ í˜„ì¬ URL: %s\n", currentURL)

	// === Username ===
	log.Printf("ğŸ” Finding username...")
	username := findTextByXPath(wd, `//article//a[starts-with(@href, "/") and contains(., "@")]`)
	log.Printf("ğŸ‘¤ Username: %s", username)
	// === Nickname ===
	log.Printf("ğŸ” Finding nickname...")
	nickname := findTextByXPath(wd, `//article//div[@dir="ltr"]//span/span`)
	log.Printf("ğŸ‘¤ Nickname: %s", nickname)
	// === Profile Image ===
	log.Printf("ğŸ” Finding profile image...")
	profileImg := findAttrByXPath(wd, `/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/section/div/div/div[1]/div/div/article/div/div/div[2]/div[1]/div[1]/div/div/div/div[2]/div/div[2]/div/a/div[3]/div/div[2]/div/img`, "src")
	log.Printf("ğŸ‘¤ Profile Image: %s", profileImg)
	// === Meta Tag ===
	log.Printf("ğŸ” Finding meta tag...")
	metaTag := findAttrByXPath(wd, `//meta[@property='og:title']`, "content")
	log.Printf("ğŸ· Meta Tag: %s", strings.ReplaceAll(metaTag, "\n", " "))
	// === Tweet Text ===
	log.Printf("ğŸ” Finding tweet text...")
	text := findTextByXPath(wd, `/html/body/div[1]/div/div/div[2]/main/div/div/div/div/div/section/div/div/div[1]/div/div/article/div/div/div[3]/div[1]/div/div`)
	log.Printf("ğŸ“ Tweet Text: %s", strings.ReplaceAll(text, "\n", " "))

	// === Images (all) ===
	log.Printf("ğŸ” Finding images...")
	var images []string
	imgElements, _ := wd.FindElements(selenium.ByXPATH, `//img[contains(@src, 'https://pbs.twimg.com/media')]`)
	for _, img := range imgElements {
		src, _ := img.GetAttribute("src")
		images = append(images, src)
	}

	// === All links in tweet ===
	log.Printf("ğŸ” Finding links...")
	linkElems, err := wd.FindElements(selenium.ByXPATH, `//article//a`)
	var links []string

	if err == nil {

		re := regexp.MustCompile(`[a-zA-Z0-9/-]*\.[a-zA-Z0-9/-]+[a-zA-Z0-9./-]*`) // ë§í¬ ì¶”ì¶œ ì •ê·œì‹. ì´ê±¸ ì•ˆ í•  ê²½ìš° ê²°ê³¼  Links:[ Xylo @xxylolo #ì»¤ë¯¸ì…˜ #rt http://kre.pe/nKn1 https://open.kakao.com/o/sr5J0Vmh  ì˜¤í›„ 4:48 Â· 2025ë…„ 3ì›” 21ì¼]
		// ğŸ’¡ íŒ: href ë¥¼ ì“°ëŠ” ê²Œ ë” ì •í™•í•˜ê¸´ í•´
		// ì¼ë¶€ íŠ¸ìœ—ì€ <a> íƒœê·¸ì— í…ìŠ¤íŠ¸ê°€ ì—†ê³ , href ì†ì„±ì—ë§Œ URLì´ ìˆëŠ” ê²½ìš°ë„ ìˆì–´ì„œ:

		// href, err := el.GetAttribute("href")
		// if err == nil && strings.Contains(href, "t.co") {
		//     links = append(links, href)
		// }
		// í•„ìš”í•˜ë©´ text + href ì¡°í•©ìœ¼ë¡œë„ ë§Œë“¤ ìˆ˜ ìˆì–´.

		for _, el := range linkElems {
			linkText, _ := el.Text()
			match := re.FindString(linkText)
			if match != "" {
				link := "https:" + match
				// ì¤‘ë³µ ì œê±° ë˜ëŠ” í•„í„°ë§ í•„ìš” ì‹œ ì—¬ê¸°ì— ì²˜ë¦¬
				links = append(links, link)
			}
		}
	}

	log.Printf("ğŸ–¼ Images: %v", images)
	log.Printf("ğŸ”— Links: %v", links)
	log.Printf("âœ… í¬ë¡¤ë§ ì™„ë£Œ: %s", url)

	return &TweetData{
		Text:           text,
		Images:         images,
		Username:       username,
		UserNickname:   nickname,
		UserProfileImg: profileImg,
		MetaTag:        metaTag,
		Links:          links,
	}, nil
}

func waitForPageLoad(wd selenium.WebDriver, timeoutSeconds int) error {
	timeout := time.Duration(timeoutSeconds) * time.Second
	endTime := time.Now().Add(timeout)
	for {
		state, err := wd.ExecuteScript("return document.readyState", nil)
		if err == nil && state == "complete" {
			return nil
		}
		if time.Now().After(endTime) {
			return errors.New("timeout waiting for page load")
		}
		time.Sleep(500 * time.Millisecond)
	}

}

// metaScrapeëŠ” HTTP í•¸ë“¤ëŸ¬ í•¨ìˆ˜ë¡œ, URL íŒŒë¼ë¯¸í„°ì—ì„œ ëŒ€ìƒ í˜ì´ì§€ì˜ URLì„ ë°›ì•„ í•´ë‹¹ í˜ì´ì§€ì˜ ë©”íƒ€ë°ì´í„°(og:title, og:image, og:description)ë¥¼ ìŠ¤í¬ë©í•©ë‹ˆë‹¤.
func ScrapeMeta(wd selenium.WebDriver, pageURL string) (interface{}, error) {

	log.Printf("ğŸ“¥ í¬ë¡¤ë§ ì‹œì‘: %s", pageURL)

	// ìŠ¤í¬ë©ì— ê±¸ë¦° ì‹œê°„ ì²´í¬ë¥¼ ìœ„í•´ í˜„ì¬ ì‹œê°„ ì €ì¥
	startTime := time.Now()

	// ë©”íƒ€ ë°ì´í„°ë¥¼ ì €ì¥í•  ë§µ
	metaData := map[string]string{}

	// í˜ì´ì§€ ë¡œë”©
	if err := wd.Get(pageURL); err != nil {
		return nil, err
	}

	// í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
	if err := waitForPageLoad(wd, 5); err != nil {
		return nil, fmt.Errorf("failed to wait for page load: %v", err)
	}

	// ì—¬ê¸°ê¹Œì§€ ê±¸ë¦° ì‹œê°„ ì²´í¬
	log.Printf("âœ… í˜ì´ì§€ ë¡œë”© ì™„ë£Œ. ê±¸ë¦° ì‹œê°„: %v", time.Since(startTime))

	// og:title ì¶”ì¶œ (ìš°ì„ , ì—†ìœ¼ë©´ <title> íƒœê·¸ë¡œ ëŒ€ì²´)
	// page source ê°€ notionì¸ ê²½ìš° title íƒœê·¸ë¥¼ ìš°ì„ í•¨
	if strings.Contains(pageURL, "notion.so") {
		titleElem, err := wd.FindElement(selenium.ByXPATH, `//title`)
		if err != nil {
			return nil, fmt.Errorf("failed to find title element: %v", err)
		}
		metaData["title"], err = titleElem.Text()
		if err != nil {
			metaData["title"] = ""
		}
	} else {
		titleElem, err := wd.FindElement(selenium.ByXPATH, `//meta[@property="og:title"]`)
		if err != nil {
			titleElem, err = wd.FindElement(selenium.ByXPATH, `//head/title`)
			if err != nil {
				return nil, fmt.Errorf("failed to find title element: %v", err)
			}
			metaData["title"], err = titleElem.Text()
			if err != nil {
				metaData["title"] = ""
			}
		} else {
			metaData["title"], err = titleElem.GetAttribute("content")
			if err != nil {
				metaData["title"] = ""
			}
		}
	}

	log.Printf("ğŸ· Title: %s", metaData["title"])

	// og:image ì¶”ì¶œ (ìš°ì„ , ì—†ìœ¼ë©´ meta[name="image"]ë¡œ ëŒ€ì²´)
	imageElem, err := wd.FindElement(selenium.ByXPATH, `//meta[@property="og:image"]`)
	if err != nil {
		imageElem, err = wd.FindElement(selenium.ByXPATH, `//meta[@name="image"]`)
		if err != nil {
			log.Printf("Warning: Failed to find image element: %v", err)
			metaData["img"] = ""
			return metaData, nil // Return early if no image element is found
		}
	}
	if imageElem != nil {
		metaData["img"], err = imageElem.GetAttribute("content")
		if err != nil {
			metaData["img"] = ""
		}
	} else {
		metaData["img"] = ""
	}
	log.Printf("ğŸ–¼ Image: %s", metaData["img"])

	// og:description ì¶”ì¶œ (ìš°ì„ , ì—†ìœ¼ë©´ meta[name="description"]ë¡œ ëŒ€ì²´)
	descElem, err := wd.FindElement(selenium.ByXPATH, `//meta[@property="og:description"]`)
	if err != nil {
		descElem, err = wd.FindElement(selenium.ByCSSSelector, `meta[name="description"]`)
		if err != nil {
			log.Printf("Warning: Failed to find description element: %v", err)
			metaData["description"] = ""
			return metaData, nil // Return early if no description element is found
		}
	}
	if descElem != nil {
		metaData["description"], err = descElem.GetAttribute("content")
		if err != nil {
			metaData["description"] = ""
		}
	} else {
		metaData["description"] = ""
	}
	log.Printf("ğŸ“ Description: %s", metaData["description"])

	// í¬ë¡¤ë§ ì™„ë£Œ. ê±¸ë¦° ì‹œê°„ ì¶œë ¥
	log.Printf("âœ… í¬ë¡¤ë§ ì™„ë£Œ: %s  ê±¸ë¦° ì‹œê°„: %v", pageURL, time.Since(startTime))

	return metaData, nil
}
